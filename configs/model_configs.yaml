# Model Configuration File
# Each top-level key represents a model to train

xgboost:
  # Model initialization parameters
  init_params:
    n_estimators: 100
    max_depth: 6
    learning_rate: 0.3
    objective: "reg:squarederror"
    random_state: 42
  
  # Training parameters
  epochs: 10
  batch_size: 32
  learning_rate: 0.001  # For optimizer if applicable
  
  # Additional model-specific parameters
  early_stopping_rounds: 10
  eval_metric: "rmse"

lightgbm:
  init_params:
    objective: "regression"
    learning_rate: 0.05
    num_leaves: 31
    metric: ["l2", "mae"]
    verbosity: -1
  epochs: 100
  batch_size: null  # Not used for LightGBM

neural_network:
  init_params:
    hidden_size: 64
    learning_rate: 0.001
  epochs: 30
  batch_size: 32
